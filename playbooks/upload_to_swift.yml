---
- hosts: localhost
  connection: local
  gather_facts: False
  vars:
    region: "DFW"
    cloud_name: "public_cloud"
    # 30 days
    retention: 2592000
  tasks:
    - name: Set the archive base name
      set_fact:
        archive_base_name: "{{ job_name }}_{{ build_number }}"

    - name: Move artifacts dir so that downloaded archives have a useful name
      shell: mv "{{ artifacts_dir | basename }}" "{{ archive_base_name }}"
      args:
        chdir: "{{ artifacts_dir | dirname }}"

    - name: Set the archive directory
      set_fact:
        adir: "{{ artifacts_dir | dirname }}/{{archive_base_name}}"

    # Links are unlikely to work when expanded on a different
    # system so remove them. Create a list of removed links
    # to give users a clue as to why their file is missing.
    # Also swift client fails on dangling links.
    - name: Remove links from artifacts
      shell: |
        find {{ adir | basename }} \
          -type l \
          -print \
          -delete \
          | tee {{ adir | basename }}/removedlinks.txt
      args:
        chdir: "{{ adir |dirname }}"
      register: removed_links

    # This task runs async while the individual files are being uploaded
    # then when compression is complete, the resultant archive is uploaded.
    # 3 Hour Timeout
    - name: Create archive asynchronously
      shell: "tar -c {{ adir | basename }} | gzip --fast > {{archive_base_name}}.tar.gz"
      args:
        chdir: "{{ adir | dirname }}"
      async: 10800
      poll: 0
      register: create_archive_async
      tags:
        - skip_ansible_lint

    - name: Create a Cloud Files container
      os_object:
        container: "{{ container }}"
        container_access: "public"
        region_name: "{{ region }}"
        cloud: "{{ cloud_name }}"
      register: _create_container
      until: _create_container | success
      retries: 5
      delay: 10

    - name: Authenticate to the cloud and retrieve the service catalog
      os_auth:
        cloud: "{{ cloud_name }}"
        region_name: "{{ region }}"
      no_log: true
      register: _auth
      until: (_auth | success) and (auth_token is defined) and (service_catalog is defined)
      retries: 5
      delay: 10

    - name: Extract object-store service catalog
      set_fact:
        object_store: "{{ service_catalog | selectattr('type', 'equalto', 'object-store') | first }}"

    - name: Determine the object-store service endpoint URL for the region
      set_fact:
        object_store_url: "{{ (object_store['endpoints'] | selectattr('region', 'equalto', region ) | first)['publicURL']}}"

    - name: Extract object-cdn service catalog
      set_fact:
        object_cdn: "{{ service_catalog | selectattr('type', 'equalto', 'rax:object-cdn') | first }}"

    - name: Determine the object-cdn service endpoint URL for the region
      set_fact:
        object_cdn_url: "{{ (object_cdn['endpoints'] | selectattr('region', 'equalto', region) | first)['publicURL'] }}/{{ container }}"

    - name: Enable CDN for the Cloud Files container
      uri:
        url: "{{ object_cdn_url }}"
        method: PUT
        headers:
          X-AUTH-TOKEN: "{{ auth_token }}"
          X-Cdn-Enabled: True
        # 201 (Created): The container was CDN-enabled as requested.
        # 202 (Accepted): The container was already CDN-enabled.
        # 204 (No Content): The container was CDN-enabled as requested, but has no content.
        status_code: "201, 202, 204"
      register: _enable_cdn
      until: (_enable_cdn | success) and ('x_cdn_ssl_uri' in _enable_cdn)
      retries: 5
      delay: 10

    - name: Set fact for the user-accessible CDN URL for the container
      set_fact:
        container_public_url: "{{ _enable_cdn['x_cdn_ssl_uri'] }}"

    # In order for uploaded files to be browsable:
    # 1. Static hosting must be enabled (this links index.html to requests for container/)
    # 2. CDN must be enabled (to allow anonymous http access to the container)
    # 3. An index page must be generated and/or web listings enabled.
    - name: Enable static web hosting
      uri:
        url: "{{ object_store_url }}/{{ container }}"
        method: POST
        headers:
          X-AUTH-TOKEN: "{{ auth_token }}"
          X-Container-Meta-Web-Index: index.html
          X-Container-Meta-Web-Listings: True
        # 204 (No Content): The container was enabled as requested.
        status_code: 204
      register: _enable_static_hosting
      until: _enable_static_hosting | success
      retries: 5
      delay: 10

    # Do this before generating index.html, styles.css and data.json
    # So they don't show up on the final page.
    - name: Generate file list with sizes for index page data
      shell: |
        find . \
          -type f \
          -mindepth 1 \
          -exec ls -l {} \; \
        |sed 's+\./++g'
      args:
        chdir: "{{ adir }}"
      register: file_list

    - name: Copy index.html
      copy:
        src: templates/artifact/index.html
        dest: "{{ adir }}/index.html"

    - name: Copy style.css
      copy:
        src: templates/artifact/styles.css
        dest: "{{ adir }}/styles.css"

    # The ansible os_object module does not currently support setting
    # the object expiration header field, nor does it do threaded uploads
    # (which make this much faster), so we use the swift client instead.
    # Checksum validation is also disabled to improve upload speed.
    - name: Upload Artifacts to Cloud Files
      command: >-
        swift upload {{ container }} {{ adir | basename }}
        --object-threads 100
        --ignore-checksum
        --header 'X-Delete-After:{{ retention }}'
      args:
        chdir: "{{ adir |dirname }}"
      environment:
        OS_AUTH_TOKEN: "{{ auth_token }}"
        OS_STORAGE_URL: "{{ (object_store['endpoints'] | selectattr('region', 'equalto', region) | first)['publicURL'] }}"
      # TODO(odyssey4me):
      # Consider removing '--ignore-checksum' and adding '--skip-identical'
      # and/or '--changed', then removing the 'failed_when' below and adding
      # retry/until to improve the chances of success.
      failed_when: false
      register: artifact_upload

    # this is json data containing metadata and a list of files
    # that will be downloaded by index.html
    # and used to display a list of available artifacts
    - name: Generate data.json
      copy:
        content: |
          {
            "job_name": "{{ job_name }}",
            "build_number": "{{ build_number }}",
            "archive_base_name": "{{ archive_base_name }}",
            "container_public_url": "{{ container_public_url}}",
            "removed_links_count": {{ removed_links.stdout_lines|count }},
            "failed_uploads": [
              {% for line in artifact_upload.stderr_lines %}
                "{{ line }}"{{ "," if not loop.last else "" }}
              {% endfor %}
            ],
            "files": [
              {% for file_line in file_list.stdout_lines %}
                {% set file_list = file_line.split() %}
                {% if file_list|length > 3 %}
                  {
                    "path": "{{file_list[-1]}}",
                    "size": {{file_list[4]}}
                  }{{ "," if not loop.last else "" }}
                {% endif %}
              {% endfor %}
            ],
            "archives": [
              "{{ container_public_url }}/{{ archive_base_name }}.tar.gz"
            ]
          }
        dest: "{{ adir }}/data.json"

    # The ansible os_object module does not currently support setting
    # the object expiration header field, nor does it do threaded uploads
    # (which make this much faster), so we use the swift client instead.
    - name: Upload index data (data.json) to Cloud Files
      command: >-
        swift upload {{ container }} {{ adir | basename }}/data.json
        --header 'X-Delete-After: {{ retention }}'
      args:
        chdir: "{{ adir | dirname }}"
      environment:
        OS_AUTH_TOKEN: "{{ auth_token }}"
        OS_STORAGE_URL: "{{ (object_store['endpoints'] | selectattr('region', 'equalto', region) | first)['publicURL'] }}"
      register: upload_data
      until: upload_data | success
      retries: 5
      delay: 10

    - name: Wait for async archive creation to complete
      async_status:
        jid: "{{ create_archive_async.ansible_job_id }}"
      register: caa
      until: caa.finished
      retries: 180
      delay: 60

    # The ansible os_object module does not currently support setting
    # the object expiration header field, nor does it do threaded uploads
    # (which make this much faster), so we use the swift client instead.
    - name: Upload archive to Cloud Files
      command: >-
        swift upload {{ container }} {{ archive_base_name }}.tar.gz
        --header 'X-Delete-After: {{ retention }}'
      args:
        chdir: "{{ adir | dirname }}"
      environment:
        OS_AUTH_TOKEN: "{{ auth_token }}"
        OS_STORAGE_URL: "{{ (object_store['endpoints'] | selectattr('region', 'equalto', region) | first)['publicURL'] }}"
      register: upload_archive
      until: upload_archive | success
      retries: 5
      delay: 10

    # This is used by common.archive_artifacts to put the link into the
    # build description.
    - name: "Write public url file"
      shell: |
        echo "{{ container_public_url }}/{{archive_base_name}}/index.html" > ${WORKSPACE}/artifact_public_url
